{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "# General information\n",
    "This kernel is dedicated to EDA of [Dota 2 Winner Prediction Competition ](https://www.kaggle.com/c/mlcourse-dota2-win-prediction)\n",
    "\n",
    "We are provided with prepared data and described features as well as with a lot of \"raw\" json data. We need to predict winner of the game. \n",
    "Evaluation metric is [ROC-AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc). \n",
    "\n",
    "<left><img src='https://kor.ill.in.ua/m/610x385/1848785.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "To simplify you navigation through this kernel: \n",
    "\n",
    "* [Main data exploration](#maindata)\n",
    "  * [Target distribution](#Target)\n",
    "  * [General features](#Generalfeatures)\n",
    "  * [Coordinates features](#Coordinatesfeatures)\n",
    "  * [T-SNE on means coordinates features](#TSNE)\n",
    "  * [KDA](#KDA)\n",
    "* [Models comparison](#simplemodels)\n",
    "* [LGBM feature importance](#FeatureImportance)\n",
    "* [Submission](#Submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleksey\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,Ridge, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "#import shap\n",
    "# load JS visualization code to notebook\n",
    "#shap.initjs()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/sample_submission.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../input/sample_submission.csv' does not exist"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PATH_TO_DATA = '../input/'\n",
    "\n",
    "sample_submission = pd.read_csv(os.path.join(PATH_TO_DATA, 'sample_submission.csv'), \n",
    "                                    index_col='match_id_hash')\n",
    "df_train_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_features.csv'), \n",
    "                                    index_col='match_id_hash')\n",
    "df_train_targets = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_targets.csv'), \n",
    "                                   index_col='match_id_hash')\n",
    "df_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'), \n",
    "                                   index_col='match_id_hash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main data exploration\n",
    "<div id=\"maindata\">\n",
    "</div>\n",
    "\n",
    "In this part I'll focus on features created by organizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5e74e348dca0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_train_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train_features' is not defined"
     ]
    }
   ],
   "source": [
    "df_train_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_targets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of Training set: {0}\\nShape of Test set: {1}'.format(df_train_features.shape,df_test_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have almost 40k entries in train dataset and we need to predict results of other 10k battles.\n",
    "\n",
    "** UPD: ** Thanks to  [@sonfire](https://www.kaggle.com/sonfire), [@ecdrid](https://www.kaggle.com/adityaecdrid) and [@ambisinistra](https://www.kaggle.com/ambisinistra) who helps me to understand some features in `df_train_targets`. <br>\n",
    "* `time_remaining` means how much time remains till the end of the game at the point of time at which all characteristics and statistics shown. Indeed, if you'll sum `game_time` and `time_remaining` you receive exactly `duration` of the game. <br>\n",
    "* `next_roshan_team` tell us about next team after that point of time which will take roshan.\n",
    "\n",
    "Maybe I have to read more about Dota, they have competitions with [prizes](http://dota2.prizetrac.kr/) more than on Kaggle. \n",
    "\n",
    "![Hm](http://img4.wikia.nocookie.net/__cb20150117182228/plantsvszombies/images/5/57/Wait-what.jpg)\n",
    "\n",
    "Just kiddin :) \n",
    "\n",
    "Let's continue, first I'll select target and then divide features on groups and observe them and their correllation with target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target \n",
    "<div id=\"Target\">\n",
    "As we know ROC-AUC is almost robust to class imbalance but let's see how it's distributed to better understand data: \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.Series(df_train_targets['radiant_win'].map({True: 1, False: 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(target);\n",
    "plt.title('Target distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General features\n",
    "<div id=\"Generalfeatures\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_features = ['game_time', 'game_mode', 'lobby_type', 'objectives_len', 'chat_len']\n",
    "gen_feat_df = df_train_features[general_features].copy()\n",
    "gen_feat_df['target'] = target\n",
    "plt.figure(figsize=(8, 5));\n",
    "ax = sns.heatmap(gen_feat_df.corr(),annot=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a little notice if you prefer other view of heatmap (check out [documentation](https://seaborn.pydata.org/generated/seaborn.heatmap.html) for more):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5));\n",
    "mask = np.zeros_like(gen_feat_df.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(gen_feat_df.corr(), mask=mask,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see correlation between target and general features is low, which seems to be logical. \n",
    "Game time or type of the game, as far as I know it, shouldn't affect much on winning side. \n",
    "Let's move to more interesting features and first take a look on map: \n",
    "\n",
    "![Dota 2 Map](https://habrastorage.org/webt/vq/h2/9c/vqh29cm1vd-69blhriyqr98saww.png)\n",
    "\n",
    "As description said `The goal is to destroy the opponent's fountain. No draws are possible in Dota 2.` which means that coordinates could be useful.\n",
    "Logic is the following: team which is on the enemy fonte at the end of the game won."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinates features\n",
    "<div id=\"Coordinatesfeatures\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 10 features correlated with target (abs values):')\n",
    "print(abs(df_train_features.corrwith(target)).sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have no idea why there is no single x coordinate feature in top 10. Who have an idea pleas share in comments! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_y_coord = ['r{0}_y'.format(i) for i in range(1,6)]\n",
    "r_x_coord = ['r{0}_x'.format(i) for i in range(1,6)]\n",
    "r_coord = r_y_coord+r_x_coord\n",
    "\n",
    "d_y_coord = ['d{0}_y'.format(i) for i in range(1,6)]\n",
    "d_x_coord = ['d{0}_x'.format(i) for i in range(1,6)]\n",
    "d_coord = d_y_coord+d_x_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_feat_df = df_train_features[r_coord+d_coord].copy()\n",
    "coord_feat_df['target'] = target\n",
    "plt.figure(figsize=(16, 10));\n",
    "ax = sns.heatmap(coord_feat_df.corr(),annot=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i decided to investigate which exactly values it takes, and was surprised that there is no 0 coordinates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min y coordinate for Radiant: {0}'.format(coord_feat_df[r_y_coord].min(axis=0).sort_values(ascending=True)[0:1].values))\n",
    "print('Max y coordinate for Radiant: {0}'.format(coord_feat_df[r_y_coord].max(axis=0).sort_values(ascending=False)[0:1].values)) \n",
    "print('Min x coordinate for Radiant: {0}'.format(coord_feat_df[r_x_coord].min(axis=0).sort_values(ascending=True)[0:1].values))\n",
    "print('Max x coordinate for Radiant: {0}'.format(coord_feat_df[r_x_coord].max(axis=0).sort_values(ascending=False)[0:1].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min y coordinate for Dire: {0}'.format(coord_feat_df[d_y_coord].min(axis=0).sort_values(ascending=True)[0:1].values))\n",
    "print('Max y coordinate for Dire: {0}'.format(coord_feat_df[d_y_coord].max(axis=0).sort_values(ascending=False)[0:1].values)) \n",
    "print('Min x coordinate for Dire: {0}'.format(coord_feat_df[d_x_coord].min(axis=0).sort_values(ascending=True)[0:1].values))\n",
    "print('Max x coordinate for Dire: {0}'.format(coord_feat_df[d_x_coord].max(axis=0).sort_values(ascending=False)[0:1].values)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that range for y's finishes is: 116 while for x's: 122. \n",
    "This means map is not completely symmetrical. \n",
    "Let's see now how this values differs for Radiant and Dire victories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/38783027/jupyter-notebook-display-two-pandas-tables-side-by-side\n",
    "from IPython.display import display_html \n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_side_by_side(coord_feat_df[coord_feat_df['target']==1].describe().T,coord_feat_df[coord_feat_df['target']==0].describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation table above we see some groups of features. <br>Let's manually unite them using mean.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_feat_df_mean = coord_feat_df.copy()\n",
    "coord_feat_df_mean['target'] = target\n",
    "\n",
    "coord_feat_df_mean['r_y_mean'] = coord_feat_df_mean[r_y_coord].mean(axis=1)\n",
    "coord_feat_df_mean['r_x_mean'] = coord_feat_df_mean[r_x_coord].mean(axis=1)\n",
    "coord_feat_df_mean['d_y_mean'] = coord_feat_df_mean[d_y_coord].mean(axis=1)\n",
    "coord_feat_df_mean['d_x_mean'] = coord_feat_df_mean[d_x_coord].mean(axis=1)\n",
    "mean_cols = ['r_y_mean', 'r_x_mean', 'd_y_mean', 'd_x_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_feat_df_mean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5));\n",
    "ax = sns.heatmap(coord_feat_df_mean[mean_cols+['target']].corr(),annot=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now show how this mean coordinates features corresponds with each other and with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.pairplot(coord_feat_df_mean[mean_cols+['target']])\n",
    "sns_plot.savefig('pairplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE on means coordinates features\n",
    "<div id=\"TSNE\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This take a lot of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsne = TSNE(random_state=17)\n",
    "tsne_representation = tsne.fit_transform(coord_feat_df_mean[mean_cols]) #https://habr.com/ru/company/ods/blog/323210/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne_representation[:, 0], tsne_representation[:, 1], \n",
    "            c=coord_feat_df_mean['target'].map({0: 'blue', 1: 'orange'}));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that points are cross each other, but there are at least 2 clusters which we could see in top left and top right corner. <br>\n",
    "Might try to find this 2 clusters based on mean coordinates features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDA (Kills|Deaths|Assists) \n",
    "<div id=\"KDA\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create another separate DataFrame to analyze kills, death and assists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "r_kills = ['r{0}_kills'.format(i) for i in range(1,6)]\n",
    "r_deaths = ['r{0}_deaths'.format(i) for i in range(1,6)]\n",
    "r_assists = ['r{0}_assists'.format(i) for i in range(1,6)]\n",
    "r_kda = r_kills+r_deaths+r_assists\n",
    "\n",
    "d_kills = ['d{0}_kills'.format(i) for i in range(1,6)]\n",
    "d_deaths = ['d{0}_deaths'.format(i) for i in range(1,6)]\n",
    "d_assists = ['d{0}_assists'.format(i) for i in range(1,6)]\n",
    "d_kda = d_kills+d_deaths+d_assists\n",
    "\n",
    "kda_feat_df = df_train_features[r_kda+d_kda].copy()\n",
    "kda_feat_df['target'] = target\n",
    "\n",
    "kda_feat_df['r_tot_kills'] = kda_feat_df[r_kills].sum(axis=1)\n",
    "kda_feat_df['r_tot_deaths'] = kda_feat_df[r_deaths].sum(axis=1)\n",
    "kda_feat_df['r_tot_assists'] = kda_feat_df[r_assists].sum(axis=1)\n",
    "\n",
    "kda_feat_df['d_tot_kills'] = kda_feat_df[d_kills].sum(axis=1)\n",
    "kda_feat_df['d_tot_deaths'] = kda_feat_df[d_deaths].sum(axis=1)\n",
    "kda_feat_df['d_tot_assists'] = kda_feat_df[d_assists].sum(axis=1)\n",
    "\n",
    "tot_cols = ['r_tot_kills', 'r_tot_deaths', 'r_tot_assists', 'd_tot_kills', 'd_tot_deaths', 'd_tot_assists']\n",
    "\n",
    "display(kda_feat_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5));\n",
    "ax = sns.heatmap(kda_feat_df[tot_cols+['target']].corr(),annot=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KDA in dota is [calculated](https://steamcommunity.com/app/570/discussions/0/3307213006841396427/ ) as: (K+A)/D \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kda_feat_df['r_kda'] = (kda_feat_df['r_tot_kills']+kda_feat_df['r_tot_assists'])/kda_feat_df['r_tot_deaths']\n",
    "kda_feat_df['d_kda'] = (kda_feat_df['d_tot_kills']+kda_feat_df['d_tot_assists'])/kda_feat_df['d_tot_deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4.8, 3));\n",
    "ax = sns.heatmap(kda_feat_df[['r_kda','d_kda','target']].corr(),annot=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other feauteres could be analyzed in the same way. <br>\n",
    "Even more data is stored in JSON files. <br>\n",
    "Now let's implement and compare few models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple models comparison\n",
    "<div id=\"simplemodels\">\n",
    "First, I am preparing data for learning and setting cross validation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_features\n",
    "y = df_train_targets['radiant_win']\n",
    "X_test = df_test_features\n",
    "y_cat = pd.Series(df_train_targets['radiant_win'].map({True: 1, False: 0})) #catboost doesn't understand True,False \n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=17) #for holdout, don't use in kernel\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)\n",
    "cv = ShuffleSplit(n_splits=n_fold, test_size=0.3, random_state=17) #same as in https://www.kaggle.com/c/mlcourse-dota2-win-prediction/kernels starter kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now will use following models without hyperparams: \n",
    "\n",
    "RF, LGBM, XGB, CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100, n_jobs=4,\n",
    "                                   max_depth=None, random_state=17)\n",
    "\n",
    "# calcuate ROC-AUC for each split\n",
    "cv_scores_rf = cross_val_score(model_rf, X, y, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_lgb = LGBMClassifier(random_state=17)\n",
    "cv_scores_lgb = cross_val_score(model_lgb, X, y, cv=cv, \n",
    "                                scoring='roc_auc', n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(random_state=17)\n",
    "cv_scores_xgb = cross_val_score(model_xgb, X, y, cv=cv,\n",
    "                                scoring='roc_auc', n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell runs ~ 13 min (it freezes completely with n_jobs not equal to 1 for unknown reason). <br>\n",
    "It's definitely better and faster to use native CatBoost CV than `sklearn` one. <br>\n",
    "You could check my [kernel](https://www.kaggle.com/vchulski/catboost-and-shap-for-dota-2-winner-prediction) dedicated to CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "model_cat = CatBoostClassifier(random_state=17,silent=True)\n",
    "cv_scores_cat = cross_val_score(model_cat, X, y_cat, cv=cv,\n",
    "                                scoring='roc_auc', n_jobs=1) #pay attention n_jobs=1 here, just freezes with any other value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(data={'RF': cv_scores_rf, 'LGB':cv_scores_lgb, 'XGB':cv_scores_xgb, 'CAT':cv_scores_cat})\n",
    "display_side_by_side(cv_results, cv_results.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see CatBoost gives best results among tested algorithms - but it's very rough comparison.After adding hyperparams this could change.\n",
    "Anyway, this gives some hint which models we definetly should try. \n",
    "\n",
    "Also, we see how fast LGBM is. I am not counting CatBoost which I will test later, but it's even 2 times faster than RF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "<div id=\"FeatureImportance\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just visit https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "#https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc\n",
    "params = {#'num_leaves': 31, # number of leaves in full tree (31 by default) \n",
    "         'learning_rate': 0.01, #this determines the impact of each tree on the final outcome. \n",
    "\n",
    "         'min_data_in_leaf': 50,\n",
    "         'min_sum_hessian_in_leaf': 12.0,\n",
    "         'objective': 'binary', \n",
    "         'max_depth': -1,\n",
    "         'boosting': 'gbdt', #'dart' \n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.81,\n",
    "         'boost_from_average':'false',\n",
    "         'bagging_seed': 17,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# this part is based on great kernel https://www.kaggle.com/artgor/seismic-data-eda-and-baseline by @artgor\n",
    "oof = np.zeros(len(X))\n",
    "prediction = np.zeros(len(X_test))\n",
    "scores = []\n",
    "feature_importance = pd.DataFrame()\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    model = LGBMClassifier(**params, n_estimators = 2000, nthread = 5, n_jobs = -1)\n",
    "    model.fit(X_train, y_train, \n",
    "              eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='auc',\n",
    "              verbose=200, early_stopping_rounds=200)\n",
    "            \n",
    "    y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "    y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n",
    "        \n",
    "    oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "    scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "    prediction += y_pred    \n",
    "    \n",
    "    # feature importance\n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"feature\"] = X.columns\n",
    "    fold_importance[\"importance\"] = model.feature_importances_\n",
    "    fold_importance[\"fold\"] = fold_n + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "prediction /= n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "feature_importance[\"importance\"] /= n_fold\n",
    "    \n",
    "cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "            by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14, 16));\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "plt.title('LGB Features (avg over folds)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it seems that gold is main feature in the game. \n",
    "\n",
    "But pay attention, results can be different based on parameters. \n",
    "Check out [this](https://www.kaggle.com/shokhan/lightgbm-starter-code) kernel for instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "<div id=\"Submission\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't share blend solution and that's why I will public simple LGB with almost random parameters, but I bet you will do better than me :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(random_state=17)\n",
    "lgb.fit(X, y)\n",
    "\n",
    "X_test = df_test_features.values\n",
    "y_test_pred = lgb.predict_proba(X_test)[:, 1]\n",
    "df_submission = pd.DataFrame({'radiant_win_prob': y_test_pred}, \n",
    "                                 index=df_test_features.index)\n",
    "submission_filename = 'lgb_{}.csv'.format(\n",
    "    datetime.datetime.now().strftime('%Y-%m-%d_%H-%M'))\n",
    "df_submission.to_csv(submission_filename)\n",
    "print('Submission saved to {}'.format(submission_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.head() #just to check that everything allright "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's my first ever public kernel on Kaggle so any feedback is appreciated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{"cells":[{"metadata":{},"cell_type":"markdown","source":"### In this kernel I will describe extracting different features and will create features based on hero_items. I used others kernels methods (ðŸ¤ ).\n### So I want to thank authors!"},{"metadata":{},"cell_type":"markdown","source":"![](https://pp.userapi.com/c853624/v853624637/1ae24/I7UTTli-mCk.jpg)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nfrom itertools import combinations\nimport seaborn as sns\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nPATH_TO_DATA = '../input'\n\ndf_train_features = pd.read_csv(os.path.join(PATH_TO_DATA, \n                                             'train_features.csv'), \n                                    index_col='match_id_hash')\ndf_train_targets = pd.read_csv(os.path.join(PATH_TO_DATA, \n                                            'train_targets.csv'), \n                                   index_col='match_id_hash')\ndf_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'), \n                                   index_col='match_id_hash')\n\ny = df_train_targets['radiant_win'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Representation"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"try:\n    import ujson as json\nexcept ModuleNotFoundError:\n    import json\n    print ('Please install ujson to read JSON oblects faster')\n    \ntry:\n    from tqdm import tqdm_notebook\nexcept ModuleNotFoundError:\n    tqdm_notebook = lambda x: x\n    print ('Please install tqdm to track progress with Python loops')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_matches(matches_file):\n    \n    MATCHES_COUNT = {\n        'test_matches.jsonl': 10000,\n        'train_matches.jsonl': 39675,\n    }\n    _, filename = os.path.split(matches_file)\n    total_matches = MATCHES_COUNT.get(filename)\n    \n    with open(matches_file) as fin:\n        for line in tqdm_notebook(fin, total=total_matches):\n            yield json.loads(line)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is a small example of how to look at data representation in .jsonl file"},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"json_list = [] #store data that are read\nnumber_of_rows = 50 #how many lines to read \n\n#reading data from .jsonl file\nwith open(os.path.join(PATH_TO_DATA, 'train_matches.jsonl')) as fin:\n    for i in range(number_of_rows):\n        line = fin.readline()\n        json_list.append(json.loads(line))\n        \n#how many matches to read. For example I took 1\nfor i in range(1, 2):\n  for j in range(1, 2):#there is 5 players in each team. But I want to look on only one player.\n    print(json.dumps(json_list[i]['players'][j], indent=4, sort_keys=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So from this output we can understand how data is stored and than extract data from .jsonl file. For example, let's look at items names in 'hero_inventory' field"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1, 5): #now we will look at 4 matches\n  for j in range(1, 5):#and now will take 5 players\n    print(json.dumps(list(map(lambda x: x['id'][5:], json_list[i]['players'][j]['hero_inventory'])), indent=4, sort_keys=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So this way you can understand how data is stored and how to extract it."},{"metadata":{},"cell_type":"markdown","source":"# Extracting Data"},{"metadata":{},"cell_type":"markdown","source":"Now let's extract item's for every player in every match."},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\n\n\ndef extract_features_csv(match):\n    \n    row = [\n        ('match_id_hash', match['match_id_hash']),\n    ]\n\n    for slot, player in enumerate(match['players']):\n        if slot < 5:\n            player_name = 'r%d' % (slot + 1)\n        else:\n            player_name = 'd%d' % (slot - 4)\n\n        row.append( (f'{player_name}_items', list(map(lambda x: x['id'][5:], player['hero_inventory'])) ) )\n        #here u can extract other data\n\n    return collections.OrderedDict(row)\n\n    \ndef extract_targets_csv(match, targets):\n    return collections.OrderedDict([('match_id_hash', match['match_id_hash'])] + [\n        (field, targets[field])\n        for field in ['game_time', 'radiant_win', 'duration', 'time_remaining', 'next_roshan_team']\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_features_from_jsonl(matches_file):\n  \n    df_new_features = []\n\n    # Process raw data and add new features\n    for match in read_matches(matches_file):\n        match_id_hash = match['match_id_hash']\n        features = extract_features_csv(match)\n\n        df_new_features.append(features)\n\n    df_new_features = pd.DataFrame.from_records(df_new_features).set_index('match_id_hash')\n    return df_new_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df = create_features_from_jsonl(os.path.join(PATH_TO_DATA, 'train_matches.jsonl')).fillna(0)\ntest_df = create_features_from_jsonl(os.path.join(PATH_TO_DATA, 'test_matches.jsonl')).fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's look at extracted item's data\ntrain_df['r1_items'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle as pkl\n\n#Better to save extracted data in files, because extracting takes time...\ntrain_df.to_pickle('df_train.pkl')\ntest_df.to_pickle('df_test.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"Ok, Here is the main function that will turn your arrays into features. Each value reflects how many times particular item was bought in each team."},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_items_dummies(train_df, test_df):\n    \n    full_df = pd.concat([train_df, test_df], sort=False)\n    train_size = train_df.shape[0]\n\n    for team in 'r', 'd':\n        players = [f'{team}{i}' for i in range(1, 6)]\n        item_columns = [f'{player}_items' for player in players]\n\n        d = pd.get_dummies(full_df[item_columns[0]].apply(pd.Series).stack()).sum(level=0, axis=0)\n        dindexes = d.index.values\n\n        for c in item_columns[1:]:\n            d = d.add(pd.get_dummies(full_df[c].apply(pd.Series).stack()).sum(level=0, axis=0), fill_value=0)\n            d = d.ix[dindexes]\n\n        full_df = pd.concat([full_df, d.add_prefix(f'{team}_item_')], axis=1, sort=False)\n        full_df.drop(columns=item_columns, inplace=True)\n\n    train_df = full_df.iloc[:train_size, :]\n    test_df = full_df.iloc[train_size:, :]\n\n    return train_df, test_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In DOTA there are consumble items, which just restore a small amount of hp/mana or teleports you. These items do not affect the outcome of the game, so let's remove it!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop_consumble_items(train_df, test_df):\n    \n    full_df = pd.concat([train_df, test_df], sort=False)\n    train_size = train_df.shape[0]\n\n    for team in 'r', 'd':\n        consumble_columns = ['tango', 'tpscroll', \n                             'bottle', 'flask',\n                            'enchanted_mango', 'clarity',\n                            'faerie_fire', 'ward_observer',\n                            'ward_sentry']\n        \n        starts_with = f'{team}_item_'\n        consumble_columns = [starts_with + column for column in consumble_columns]\n        full_df.drop(columns=consumble_columns, inplace=True)\n\n    train_df = full_df.iloc[:train_size, :]\n    test_df = full_df.iloc[train_size:, :]\n\n    return train_df, test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nnew_train = pd.read_pickle('df_train.pkl')\nnew_test = pd.read_pickle('df_test.pkl')\n\nnew_train, new_test = add_items_dummies(new_train, new_test)\nnew_train, new_test = drop_consumble_items(new_train, new_test)\n\ntarget = pd.DataFrame(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train.shape, target.shape, new_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features variable to look at features importance in the end\nfeatures = new_train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n        'bagging_freq': 5,  #handling overfitting\n        'bagging_fraction': 0.5,  #handling overfitting - adding some noise\n        'boost_from_average':'false',\n        'boost': 'gbdt',\n        'feature_fraction': 0.05, #handling overfitting\n        'learning_rate': 0.01,  #the changes between one auc and a better one gets really small thus a small learning rate performs better\n        'max_depth': -1,  \n        'metric':'auc',\n        'min_data_in_leaf': 50,\n        'min_sum_hessian_in_leaf': 10.0,\n        'num_leaves': 10,\n        'num_threads': 5,\n        'tree_learner': 'serial',\n        'objective': 'binary', \n        'verbosity': 1\n    }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's make a prediction. I'm using LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#divide training data into train and validaton folds\nfolds = StratifiedKFold(n_splits=5, shuffle=False, random_state=17)\n\n#placeholder for out-of-fold, i.e. validation scores\noof = np.zeros(len(new_train))\n\n#for predictions\npredictions = np.zeros(len(new_test))\n\n#and for feature importance\nfeature_importance_df = pd.DataFrame()\n\n#RUN THE LOOP OVER FOLDS\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(new_train.values, target.values)):\n    \n    X_train, y_train = new_train.iloc[trn_idx], target.iloc[trn_idx]\n    X_valid, y_valid = new_train.iloc[val_idx], target.iloc[val_idx]\n    \n    print(\"Computing Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(X_train, label = y_train)\n    val_data = lgb.Dataset(X_valid, label = y_valid)\n\n    \n    num_round = 5000 \n    verbose=1000 \n    stop=500 \n    \n    #TRAIN THE MODEL\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=verbose, early_stopping_rounds = stop)\n    \n    #CALCULATE PREDICTION FOR VALIDATION SET\n    oof[val_idx] = clf.predict(new_train.iloc[val_idx], num_iteration=clf.best_iteration)\n    \n    #FEATURE IMPORTANCE\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    #CALCULATE PREDICTIONS FOR TEST DATA, using best_iteration on the fold\n    predictions += clf.predict(new_test, num_iteration=clf.best_iteration) / folds.n_splits\n\n#print overall cross-validatino score\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Well, we got 0.76345 score. I think it's fine for only one feature[](http://) ðŸ¤”"},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n        .groupby(\"Feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:150].index)\nbest_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n\nplt.figure(figsize=(14,28))\nsns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('Features importance (averaged/folds)')\nplt.tight_layout()\nplt.savefig('FI.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission = pd.DataFrame({'radiant_win_prob': predictions}, \n                                 index=df_test_features.index)\nimport datetime\nsubmission_filename = 'submission_{}.csv'.format(\n    datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\ndf_submission.to_csv(submission_filename)\nprint('Submission saved to {}'.format(submission_filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### You can improve this feature! There is still work to do!"},{"metadata":{},"cell_type":"markdown","source":"### Please upvote!"},{"metadata":{},"cell_type":"markdown","source":"![](https://pm1.narvii.com/6711/b35fe75b3f52b585f9e3efc483aa2c3cb7ea9c5c_hq.jpg)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "## General information\n",
    "\n",
    "In this kernel I am implementing catboost and showing some methods of SHAP explainer.<br>\n",
    "For EDA check [this](https://www.kaggle.com/vchulski/dota-2-eda-and-simple-models-comparing) out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T20:16:12.545187Z",
     "start_time": "2019-11-06T20:16:02.310115Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ujson'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a19941de3802>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mujson\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ujson'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import ujson as json\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T20:16:12.550144Z",
     "start_time": "2019-11-06T20:16:08.211Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "PATH_TO_DATA = '../input/'\n",
    "\n",
    "sample_submission = pd.read_csv(os.path.join(PATH_TO_DATA, 'sample_submission.csv'), \n",
    "                                    index_col='match_id_hash')\n",
    "df_train_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_features.csv'), \n",
    "                                    index_col='match_id_hash')\n",
    "df_train_targets = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_targets.csv'), \n",
    "                                   index_col='match_id_hash')\n",
    "df_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'), \n",
    "                                   index_col='match_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of Training set: {0}\\nShape of Test set: {1}'.format(df_train_features.shape,df_test_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from Yorko kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#a helper function, we will use it in next cell\n",
    "def read_matches(matches_file):\n",
    "    \n",
    "    MATCHES_COUNT = {\n",
    "        'test_matches.jsonl': 10000,\n",
    "        'train_matches.jsonl': 39675,\n",
    "    }\n",
    "    _, filename = os.path.split(matches_file)\n",
    "    total_matches = MATCHES_COUNT.get(filename)\n",
    "    \n",
    "    with open(matches_file) as fin:\n",
    "        for line in tqdm_notebook(fin, total=total_matches):\n",
    "            yield json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "def add_new_features(df_features, matches_file):\n",
    "    \n",
    "    # Process raw data and add new features\n",
    "    for match in read_matches(matches_file):\n",
    "        match_id_hash = match['match_id_hash']\n",
    "\n",
    "        # Counting ruined towers for both teams\n",
    "        radiant_tower_kills = 0\n",
    "        dire_tower_kills = 0\n",
    "        for objective in match['objectives']:\n",
    "            if objective['type'] == 'CHAT_MESSAGE_TOWER_KILL':\n",
    "                if objective['team'] == 2:\n",
    "                    radiant_tower_kills += 1\n",
    "                if objective['team'] == 3:\n",
    "                    dire_tower_kills += 1\n",
    "\n",
    "        # Write new features\n",
    "        df_features.loc[match_id_hash, 'radiant_tower_kills'] = radiant_tower_kills\n",
    "        df_features.loc[match_id_hash, 'dire_tower_kills'] = dire_tower_kills\n",
    "        df_features.loc[match_id_hash, 'diff_tower_kills'] = radiant_tower_kills - dire_tower_kills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# copy the dataframe with features\n",
    "df_train_features_extended = df_train_features.copy()\n",
    "df_test_features_extended = df_test_features.copy()\n",
    "\n",
    "# add new features\n",
    "add_new_features(df_train_features_extended, os.path.join(PATH_TO_DATA, 'train_matches.jsonl'))\n",
    "add_new_features(df_test_features_extended, os.path.join(PATH_TO_DATA, 'test_matches.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features_extended.info() #no categorical data here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_features_extended.values\n",
    "y = df_train_targets['radiant_win'].map({True: 1, False: 0}).values\n",
    "X_test = df_test_features_extended.values\n",
    "print('Shape of Training set: ', X.shape, ' shape of target: ', y.shape, ' shape of test set: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=17) #let's use holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=400,random_seed=42,eval_metric='AUC',logging_level='Silent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproduce this to see great real time interactive graph! \n",
    "And if someone has idea how to save it and show in rendered kernel please let me know! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#https://github.com/catboost/tutorials/blob/master/python_tutorial.ipynb\n",
    "model.fit(X_train, y_train,\n",
    "    eval_set=(X_valid, y_valid),\n",
    "    #logging_level='Verbose',  # you can uncomment this for text output\n",
    "    plot=True #Uncomment and you'll see really great real time interactive graph\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From graph I saw that best iteration was on 347 iteration with 0.8060119476 result on holdout set.\n",
    "Pay attention you could also switch to logloss (on graph) - where learn line will be visible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_params = model.get_params()\n",
    "print('cv params: ', cv_params)\n",
    "cv_data = cv(\n",
    "    Pool(X, y),\n",
    "    cv_params,\n",
    "    seed=17,\n",
    "    fold_count=5,\n",
    "    plot=True #this one has much more delay, but results are awesome (you really could understand how learning was going over folds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best validation accuracy score: {:.2f}Â±{:.4f} on step {}'.format(\n",
    "    np.max(cv_data['test-AUC-mean']),\n",
    "    cv_data['test-AUC-std'][np.argmax(cv_data['test-AUC-mean'])],\n",
    "    np.argmax(cv_data['test-AUC-mean'])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, on CV we maybe need to increase number of iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(df_train_features_extended) #here I use df instead of X, because I've used df.values before \n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], df_train_features_extended.iloc[0,:]) #here I use df instead of X, because I've used df.values before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SHAP dependence plot to show the effect of a single feature across the whole dataset\n",
    "shap.dependence_plot(\"d3_gold\", shap_values, df_train_features_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "shap.summary_plot(shap_values, df_train_features_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am really impressed by the abilities of CatBoost library and SHAP explainer.\n",
    "Tower kills, deaths and gold are obviously strong features. \n",
    "\n",
    "With this instrument you could add new features in very representative view. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in my other [kernel](https://www.kaggle.com/vchulski/dota-2-eda-and-simple-models-comparing) on this competition for submission I use simple model without any hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=400,random_seed=42,eval_metric='AUC',logging_level='Silent')\n",
    "model.fit(X, y)\n",
    "\n",
    "y_test_pred = model.predict_proba(X_test)[:, 1]\n",
    "df_submission = pd.DataFrame({'radiant_win_prob': y_test_pred}, \n",
    "                                 index=df_test_features.index)\n",
    "submission_filename = 'catboost_{}.csv'.format(\n",
    "    datetime.datetime.now().strftime('%Y-%m-%d_%H-%M'))\n",
    "df_submission.to_csv(submission_filename)\n",
    "print('Submission saved to {}'.format(submission_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.head() #just to check that everything allright "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to discuss anything on this kernel in comments and upvote if it was useful. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
